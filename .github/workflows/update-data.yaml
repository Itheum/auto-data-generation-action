name: Data_Auto_Update_Tool

env:
  S3_KEY_ID: ${{ secrets.S3_KEY_ID }}
  S3_ACCESS_KEY: ${{ secrets.S3_ACCESS_KEY }}
  S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}

on:
  schedule:
    - cron: "30 23 * * *"

  push:
    branches:
      - main

  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: "pip"
      - run: |
          pip install -r requirements.txt

      - name: Data generating script
        uses: actions/upload-artifact@v3
        with:
          # You can change the artifact name to whatever you want here
          name: Data_Name
          # You can change the path to whatever your file is called here want here
          path: output/test_file.json
          retention-days: 1
        This is an example of a command that can be used to run a script, but it can be changed according to needs
        run: |
          python main.py

      - name: Upload data to S3
        uses: shallwefootball/s3-upload-action@master
        id: S3
        with:
          aws_access_key_id: ${{ env.S3_KEY_ID }}
          aws_secret_access_key: ${{ env.S3_ACCESS_KEY }}
          bucket: ${{ env.S3_BUCKET_NAME }}
          source: output/test_file.json
